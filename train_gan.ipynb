{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc4ptIkmNTnp",
        "outputId": "2f94ae3b-9712-4520-9714-e6af2063da37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n"
          ]
        }
      ],
      "source": [
        "# Install TensorFlow if not present (Colab has it by default)\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, LeakyReLU, BatchNormalization, Input, Embedding, multiply\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST data\n",
        "(X_train, y_train), (_, _) = mnist.load_data()\n",
        "X_train = (X_train.astype(np.float32) - 127.5) / 127.5  # Normalize to [-1, 1]\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "num_classes = 10\n",
        "latent_dim = 100\n",
        "img_shape = (28, 28, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQP1VwcCOEpx",
        "outputId": "9fa6a84e-a0b9-4d10-c7a4-aa00b6ceebd1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    label = Input(shape=(1,), dtype='int32')\n",
        "    label_embedding = Flatten()(Embedding(num_classes, latent_dim)(label))\n",
        "    model_input = multiply([noise, label_embedding])\n",
        "    x = Dense(256)(model_input)\n",
        "    x = LeakyReLU(negative_slope=0.2)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = LeakyReLU(negative_slope=0.2)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Dense(1024)(x)\n",
        "    x = LeakyReLU(negative_slope=0.2)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "    x = Dense(np.prod(img_shape), activation='tanh')(x)\n",
        "    img = Reshape(img_shape)(x)\n",
        "    return Model([noise, label], img)\n",
        "\n",
        "def build_discriminator():\n",
        "    img = Input(shape=img_shape)\n",
        "    label = Input(shape=(1,), dtype='int32')\n",
        "    label_embedding = Flatten()(Embedding(num_classes, np.prod(img_shape))(label))\n",
        "    flat_img = Flatten()(img)\n",
        "    model_input = multiply([flat_img, label_embedding])\n",
        "    x = Dense(512)(model_input)\n",
        "    x = LeakyReLU(negative_slope=0.2)(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = LeakyReLU(negative_slope=0.2)(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = LeakyReLU(negative_slope=0.2)(x)\n",
        "    validity = Dense(1, activation='sigmoid')(x)\n",
        "    return Model([img, label], validity)\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "C91R3TWUOI2_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = Input(shape=(latent_dim,))\n",
        "label = Input(shape=(1,))\n",
        "img = generator([noise, label])\n",
        "discriminator.trainable = False\n",
        "valid = discriminator([img, label])\n",
        "combined = Model([noise, label], valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer='adam')\n"
      ],
      "metadata": {
        "id": "7t0sOZmGOnt-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5000  # You can increase this if you have more time/resources\n",
        "batch_size = 64\n",
        "save_interval = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Train discriminator\n",
        "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "    imgs, labels = X_train[idx], y_train[idx]\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    gen_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "    gen_imgs = generator.predict([noise, gen_labels], verbose=0)\n",
        "    d_loss_real = discriminator.train_on_batch([imgs, labels], np.ones((batch_size, 1)))\n",
        "    d_loss_fake = discriminator.train_on_batch([gen_imgs, gen_labels], np.zeros((batch_size, 1)))\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "    # Train generator\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    sampled_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "    g_loss = combined.train_on_batch([noise, sampled_labels], np.ones((batch_size, 1)))\n",
        "    if epoch % save_interval == 0:\n",
        "        print(f\"{epoch} [D loss: {d_loss[0]:.4f}, acc.: {100*d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0866AFKOr4Z",
        "outputId": "f6fb5f85-9dfc-42c8-9524-4a3117133e9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [D loss: 0.6956, acc.: 37.11%] [G loss: 0.6948]\n",
            "1000 [D loss: 0.7571, acc.: 13.29%] [G loss: 0.5842]\n",
            "2000 [D loss: 0.7629, acc.: 12.92%] [G loss: 0.5743]\n",
            "3000 [D loss: 0.7652, acc.: 12.84%] [G loss: 0.5705]\n",
            "4000 [D loss: 0.7665, acc.: 12.76%] [G loss: 0.5684]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save('mnist_gan_generator.h5')\n",
        "print(\"Generator model saved as mnist_gan_generator.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5TYGf6aO_WM",
        "outputId": "7199a7aa-b2ce-4c3d-acc7-dd91d4ccb56e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator model saved as mnist_gan_generator.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('mnist_gan_generator.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MVhmuuFkPE_Y",
        "outputId": "adb537e7-9741-4785-b722-d788ff9953f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3144b645-2a73-4f4c-99a4-e412c914cd94\", \"mnist_gan_generator.h5\", 6027832)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}